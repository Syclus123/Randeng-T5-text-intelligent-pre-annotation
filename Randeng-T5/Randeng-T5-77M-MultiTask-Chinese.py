# -*- coding: utf-8 -*-

'''
-*- coding: utf-8 -*-
@File  : Randeng-T5-77M-MultiTask-Chinese.py
@Time  : 2023/11/11 22:10
'''
import torch
from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration

#####################  加载预训练模型  #######################

# pretrained_model = "IDEA-CCNL/Randeng-T5-77M-MultiTask-Chinese"
pretrained_model = "./T5-77M-CH"

special_tokens = ["<extra_id_{}>".format(i) for i in range(100)] #添加定义特殊token
tokenizer = T5Tokenizer.from_pretrained(  #T5tokenizer处理文本
    pretrained_model,
    do_lower_case=True, #是否转小写
    max_length=512,     #token最大长度
    # max_length=10240,
    truncation=True,    #是否截断输入文本以适应模型的最大长度
    additional_special_tokens=special_tokens, #添加额外的特殊token
)

config = T5Config.from_pretrained(pretrained_model) #加载预训练模型配置
model = T5ForConditionalGeneration.from_pretrained(pretrained_model, config=config) #T5生成模型，载入配置
model.resize_token_embeddings(len(tokenizer)) #调整模型的嵌入层，使其包含新的token
model.eval() #评估模式
example_dict = {
    "文本分类": {"text_a": "钢琴块3别踩白块儿3钢琴块3是一款简洁的钢琴模拟软件,在Android平台上,类似的软件还是比较多的。",
             "choices": ["相机", "影视娱乐", "棋牌中心", "新闻", "财经", "策略", "休闲益智", "教育"]},
    '新闻分类': {"text_a": "微软披露拓扑量子计算机计划！", "choices": ["故事", "文化", "娱乐", "体育", "财经", "房产", "汽车", "教育", "科技"]},
    '情感分析': {"text_a": "刚买iphone13 pro 还不到一个月，天天死机最差的一次购物体验", "choices": ["好评", "差评"]},
    '意图识别': {"text_a": "打电话给吴小军。", "choices": ["放音乐", "播放下一首", "打电话", "退出导航", "开始导航", "其他", "暂停音乐", "导航", "开导航"]},

    '语义匹配': {"text_a": "今天心情不好", "text_b": "我很不开心", "choices": ["相似", "不相似"]},
    '自然语言推理': {"text_a": "小明正在上高中", "text_b": "小明是一个初中生", "choices": ["无关", "矛盾", "蕴含"]},

    '多项选择': {"text_a": "这大家千万不能着急，我们现在只是暂时输了7分。距离比赛结束还有20多分钟呢，我们是完全有机会转败为赢的，大家加油!", "question": "说话人希望大家：",
             "choices": ["别得意", "冷静一些", "加快速度", "提前预习"]},
    '指代消解': {"text_a": "李鸣觉得董客这人，踏实得叫人难受。可因为孟野和森森太疯，他只好去找董客聊天，但在董客眼里，李鸣也是不正常，他竟然放着现成的大学不愿上。",
             "question": "【他】指的是【李鸣】吗？", "choices": ["是", "不是"]},

    '实体识别': {"text_a": "北京大学是我国的一座历史名校，坐落在海淀区，蔡元培曾经担任校长", "question": "机构"},
    '抽取式阅读理解': {"text_a": "《H》正式定档3月7日下午两点整在京东商城独家平台开启第一批5000份预售,定价230元人民币,回馈最忠实的火星歌迷,意在用精品回馈三年来跟随华晨宇音乐不离不弃的粉丝们的支持与厚爱",
                "question": "华晨宇专辑h预售价格是多少？"},
    '关键词抽取': {"text_a": "今儿在大众点评，找到了口碑不错的老茶故事私房菜。"},

    "生成式摘要": {
        "text_a": "针对传统的流量分类管理系统存在不稳定、结果反馈不及时、分类结果显示不直观等问题,设计一个基于web的在线的流量分类管理系统.该系统采用流中前5个包(排除3次握手包)所含信息作为特征值计算资源,集成一种或多种分类算法用于在线网络流量分类,应用数据可视化技术处理分类结果.实验表明:在采用适应在线分类的特征集和c4.5决策树算法做分类时,系统能快速做出分类,且精度达到94％以上;数据可视化有助于人机交互,改善分类指导."}
}

# 构造prompt的过程中，verbalizer这个占位key的内容，是通过 "/".join(choices) 拼接起来
dataset2instruction = {
    "情感分析": {
        "prompt": "{}任务：【{}】这篇文章的情感态度是什么？{}",
        "keys_order": ["subtask_type", "text_a", "verbalizer"],
        "data_type": "classification",
    },
    "文本分类": {
        "prompt": "{}任务：【{}】这篇文章的类别是什么？{}",
        "keys_order": ["subtask_type", "text_a", "verbalizer"],
        "data_type": "classification",
    },
    "新闻分类": {
        "prompt": "{}任务：【{}】这篇文章的类别是什么？{}",
        "keys_order": ["subtask_type", "text_a", "verbalizer"],
        "data_type": "classification",
    },
    "意图识别": {
        "prompt": "{}任务：【{}】这句话的意图是什么？{}",
        "keys_order": ["subtask_type", "text_a", "verbalizer"],
        "data_type": "classification",
    },
    # --------------------
    "自然语言推理": {
        "prompt": "{}任务：【{}】和【{}】，以上两句话的逻辑关系是什么？{}",
        "keys_order": ["subtask_type", "text_a", "text_b", "verbalizer"],
        "data_type": "classification",
    },
    "语义匹配": {
        "prompt": "{}任务：【{}】和【{}】，以上两句话的内容是否相似？{}",
        "keys_order": ["subtask_type", "text_a", "text_b", "verbalizer"],
        "data_type": "classification",
    },
    # -----------------------
    "指代消解": {
        "prompt": "{}任务：文章【{}】中{}{}",
        "keys_order": ["subtask_type", "text_a", "question", "verbalizer"],
        "data_type": "classification",
    },
    "多项选择": {
        "prompt": "{}任务：阅读文章【{}】问题【{}】？{}",
        "keys_order": ["subtask_type", "text_a", "question", "verbalizer"],
        "data_type": "classification",
    },
    # ------------------------
    "抽取式阅读理解": {
        "prompt": "{}任务：阅读文章【{}】问题【{}】的答案是什么？",
        "keys_order": ["subtask_type", "text_a", "question"],
        "data_type": "mrc",
    },
    "实体识别": {
        "prompt": "{}任务：找出【{}】这篇文章中所有【{}】类型的实体？",
        "keys_order": ["subtask_type", "text_a", "question"],
        "data_type": "ner",
    },
    # ------------------------
    "关键词抽取": {
        "prompt": "{}任务：【{}】这篇文章的关键词是什么？",
        "keys_order": ["subtask_type", "text_a"],
        "data_type": "keys",
    },
    "关键词识别": {
        "prompt": "{}任务：阅读文章【{}】问题【{}】{}",
        "keys_order": ["subtask_type", "text_a", "question", "verbalizer"],
        "data_type": "classification",
    },
    "生成式摘要": {
        "prompt": "{}任务：【{}】这篇文章的摘要是什么？",
        "keys_order": ["subtask_type", "text_a"],
        "data_type": "summ",
    },
}

# 构造prompt提示词格式
def get_instruction(sample):
    # 从dataset2instruction字典中获取与当前任务相关的模板
    template = dataset2instruction[sample["subtask_type"]]
    # print(template)
    # print(sample)

    # 使用模板构建prompt，通过format方法将sample中的信息填充到模板的占位符中
    sample["instruction"] = template["prompt"].format(*[
        sample[k] for k in template["keys_order"]
    ])
    print(sample["instruction"]) #构建的prompt

    return sample["instruction"]

############################################# local test ##############################################
# 传入待分析文本
# text = example_dict["文本分类"]["text_a"]
ch = 9
# 1 3 7 9
#1——文本分类任务 ，2——关键词识别任务 ，3——关键词抽取 ，4——情感分类 ，5——实体识别 ， 6——意图识别 ， 7——生成式摘要 ，8——新闻分类，9——抽取式阅读理解
if ch == 1:
    # text = "文本分类任务：【老师好！假设有一个二次方程 \( ax^2 + bx + c = 0 \)，其中 \( a, b, c \) 是实数，且 \( a \neq 0 \)。如果该方程的两个根分别是 \( x_1 \) 和 \( x_2 \)，那么这两个根 \( x_1 \) 和 \( x_2 \) 与系数 \( a, b, c \) 之间是否存在某种关系？如果存在，请详细说明这种关系，并解释其几何意义。】这篇文章的类别是什么？{机器学习/强化学习/图形学/建筑工程/经济学/流体力学/物理学/数学推理公式/金融/文学问题/教育学/代码问题/画图问题/纺织类问题/修改论文问题/数据处理问题/数据集大小}"
    text = "文本分类任务：【老师好！在当前深度学习领域，图神经网络（Graph Neural Networks, GNNs）被广泛用于图数据的学习任务，例如社交网络、分子结构分析等。在实际应用中，如何处理大规模图数据的效率问题成为一个关键挑战。请问，有哪些当前主流的方法或者技术用于加速大规模图神经网络的训练过程？这些方法的原理是什么，它们如何在实际任务中表现？在未来，我们是否可以期待更多创新的大规模图神经网络训练的加速技术的出现？】这篇文章的类别是什么？{机器学习/强化学习/图形学/建筑工程/经济学/流体力学/物理学/数学推理公式/金融/文学问题/教育学/代码问题/画图问题/纺织类问题/修改论文问题/数据处理问题/数据集大小}"
    # text = "文本分类任务：【陈老师好！大电阻悬空只是对地才考虑吗，还是5.1千欧的电阻达不到大电阻的条件，就是上面这个引脚得出高电平的结论是因为它接大电阻悬空了，还是因为本身接了VCC所以是高电平，接在VCC上的电阻反正不管大还是小那个对应的引脚都是高电平，好像不需要考虑，大电阻悬空只可能会影响到本身信号是低电平，但是接了大电阻导致引脚悬空，用高电平来判断】这篇文章的类别是什么？{机器学习/强化学习/图形学/建筑工程/经济学/流体力学/物理学/数学推理公式/金融/文学问题/教育学/代码问题/画图问题/纺织类问题/修改论文问题/数据处理问题/数据集大小/电子电路电压问题}"
    # text = "文本分类任务：【老师好，我在训练深度学习模型Transformer模型的训练过程中出现了过拟合问题，我们的数据集现在只有1G，请问是不是收集的数据量的大小出现了问题？】这篇文章的类别是什么？{机器学习/强化学习/图形学/建筑工程/经济学/流体力学/物理学/数学推理公式/金融/文学问题/教育学/代码问题/画图问题/纺织类问题/修改论文问题/数据处理问题/数据集大小}"
elif ch ==2:
    # text = "关键词识别任务：阅读文章【北京大学是我国的一座历史名校，坐落在海淀区，蔡元培曾经担任校长】问题【大学】"
    text = "关键词识别任务：【陈老师好！大电阻悬空只是对地才考虑吗，还是5.1千欧的电阻达不到大电阻的条件，就是上面这个引脚得出高电平的结论是因为它接大电阻悬空了，还是因为本身接了VCC所以是高电平，接在VCC上的电阻反正不管大还是小那个对应的引脚都是高电平，好像不需要考虑，大电阻悬空只可能会影响到本身信号是低电平，但是接了大电阻导致引脚悬空，用高电平来判断】"
    # text = "关键词识别任务：【恒生电子是一家以“让金融变简单”为使命的金融科技公司，总部位于中国杭州。恒生聚焦金融行业，致力于为证券、期货、基金、信托、保险、银行、交易所、私募等机构提供整体解决方案和服务。恒生已连续15年入选FinTech100全球金融科技百强榜单，2022年排名第24位。目前拥有超过13300名员工，其中产品技术人员占比约65%。多年来，恒生以技术服务为核心。凭借多年金融IT建设经验，以及对金融业务的深刻洞察和理解，用优质的产品与服务，持续赋能金融机构创新发展。】问题【核心技术】"
elif ch ==3:
    # text = "关键词抽取任务：【恒生电子是一家以“让金融变简单”为使命的金融科技公司，总部位于中国杭州。恒生聚焦金融行业，致力于为证券、期货、基金、信托、保险、银行、交易所、私募等机构提供整体解决方案和服务。恒生已连续15年入选FinTech100全球金融科技百强榜单，2022年排名第24位。目前拥有超过13300名员工，其中产品技术人员占比约65%。多年来，恒生以技术服务为核心。凭借多年金融IT建设经验，以及对金融业务的深刻洞察和理解，用优质的产品与服务，持续赋能金融机构创新发展。总部位于中国杭州。总部位于中国杭州。总部位于中国杭州。】这篇文章的关键词是什么？"
    # text = "关键词抽取任务：【陈老师好！我想问一个关于电阻和电压的问题，就是大电阻悬空只是对地才考虑吗，还是5.1千欧的电阻达不到大电阻的条件，就是上面这个引脚得出高电平的结论是因为它接大电阻悬空了，还是因为本身接了VCC所以是高电平，接在VCC上的电阻反正不管大还是小那个对应的引脚都是高电平，好像不需要考虑，大电阻悬空只可能会影响到本身信号是低电平，但是接了大电阻导致引脚悬空，用高电平来判断】这篇文章的关键词是什么？"
    text = "关键词抽取任务：【老师好，我想问一个关于过拟合的问题，就是昨天我在训练深度学习模型Transformer模型的训练过程中出现了过拟合问题，我们的数据集现在只有1G，请问是不是收集的数据量的大小出现了问题？】这篇文章的关键词是什么？"

    # text = ""
    # # 读取txt文件
    # file_path = 'Keywords Extraction.txt'
    # with open(file_path, 'r', encoding='utf-8') as file:
    #     content = file.read()
    # # 将文本填入模板
    # text = f"关键词抽取任务：\u200b``&#8203;``【oaicite:0】``&#8203;``\u200b这篇文章的关键词是什么？"
    # # 打印生成的文本
    # print(text)
elif ch ==4:
    text = "情感分析任务：【当我走进那间小小的咖啡馆，一股浓郁的咖啡香扑面而来，瞬间让我感到温馨和宁静。我选择了一个角落的座位，靠窗而坐，窗外是春日的暖阳，微风拂过，让人感到舒适宜人。】这篇文章的情感态度是什么？{开心/伤心}"
elif ch ==5:
    text = "实体识别任务：找出【恒生电子是一家以“让金融变简单”为使命的金融科技公司，总部位于中国杭州。恒生聚焦金融行业，致力于为证券、期货、基金、信托、保险、银行、交易所、私募等机构提供整体解决方案和服务。恒生已连续15年入选FinTech100全球金融科技百强榜单，2022年排名第24位。目前拥有超过13300名员工，其中产品技术人员占比约65%。多年来，恒生以技术服务为核心。凭借多年金融IT建设经验，以及对金融业务的深刻洞察和理解，用优质的产品与服务，持续赋能金融机构创新发展。】这篇文章中所有【地点】类型的实体？"
elif ch ==6:
    text = "意图识别任务：【尊敬的教授您好，我是学生张三，关于衬衫设计中的袖笼底点的问题，我有一些疑问，希望您能够给予指导和解答。在画衬衫的袖子时，我注意到有两种常见的方式来确定前后袖笼底点：一种方法是从原始袖笼底点出发，向下降低0.3cm，然后在这个新点出来1cm的位置处与相邻线交点。我想了解这种方式的合理性和在设计中的具体应用。另一种方法是延长袖笼弧线，找到它与侧缝多出来1cm的交点。我想了解这种方式相较于第一种方式的优势和适用场景，以及在实际设计中如何准确地执行这个步骤。同时，我也想请教您关于这两种方式的影响，例如在舒适度、穿着感和整体外观方面的差异。在实际应用中，是否存在一种方式更为推荐或者更加常见？最后，如果有其他与袖笼底点相关的设计技巧或者注意事项，我也非常希望您能够分享，以便我能够更好地理解和运用这一设计要素。非常感谢您宝贵的时间和指导，期待您的回复】这句话的意图是什么？"
    # text = "意图识别任务：【太乙中文clip多模态模型其实就是将openAI的图像编码器直接拿过来用，采用Roberta作为中文文本编码器，在Clip预训练数据的汉化版上进行了进一步的预训练。其中太乙102M的文本编码器 对应的是openAI的 VIT-patch32的图像编码器。笔者将下方两个模型下载到本地。】这句话的意图是什么？{详细介绍功能}"
elif ch ==7:
    # text = "生成式摘要任务：【在当前深度学习领域，图神经网络（Graph Neural Networks, GNNs）被广泛用于图数据的学习任务，例如社交网络、分子结构分析等。在实际应用中，如何处理大规模图数据的效率问题成为一个关键挑战。请问，有哪些当前主流的方法或者技术用于加速大规模图神经网络的训练过程？这些方法的原理是什么，它们如何在实际任务中表现？在未来，我们是否可以期待更多创新的大规模图神经网络训练的加速技术的出现？】这篇文章的摘要是什么？"
    text = "生成式摘要任务：【尊敬的教授，您好。我是学生张三，关于衬衫设计中的袖笼底点的问题，我有一些疑问，希望您能够给予指导和解答。在画衬衫的袖子时，我注意到有两种常见的方式来确定前后袖笼底点：一种方法是从原始袖笼底点出发，向下降低0.3cm，然后在这个新点出来1cm的位置处与相邻线交点。我想了解这种方式的合理性和在设计中的具体应用。另一种方法是延长袖笼弧线，找到它与侧缝多出来1cm的交点。我想了解这种方式相较于第一种方式的优势和适用场景，以及在实际设计中如何准确地执行这个步骤。同时，我也想请教您关于这两种方式的影响，例如在舒适度、穿着感和整体外观方面的差异。在实际应用中，是否存在一种方式更为推荐或者更加常见？最后，如果有其他与袖笼底点相关的设计技巧或者注意事项，我也非常希望您能够分享，以便我能够更好地理解和运用这一设计要素。非常感谢您宝贵的时间和指导，期待您的回复】这篇文章的摘要是什么？"
    # text = "生成式摘要任务：【太乙中文clip多模态模型其实就是将openAI的图像编码器直接拿过来用，采用Roberta作为中文文本编码器，在Clip预训练数据的汉化版上进行了进一步的预训练。其中太乙102M的文本编码器 对应的是openAI的 VIT-patch32的图像编码器。笔者将下方两个模型下载到本地。】这篇文章的摘要是什么？"
elif ch ==8:
    text = "新闻分类任务：【谷歌公司首席执行官表示，他们计划在未来五年内全面实现碳中和，并将投资额翻倍用于太阳能和风能等清洁能源项目。同时，亚马逊也发布了雄心勃勃的计划，承诺在2030年前投资100亿美元用于推动可再生能源的创新和发展。】这篇文章的类别是什么？{情感/娱乐/科技/知识/汽车/金融/教育/明星}"
elif ch ==9:
    text = "抽取式阅读理解任务：阅读文章【谷歌公司首席执行官表示，他们计划在未来五年内全面实现碳中和，并将投资额翻倍用于太阳能和风能等清洁能源项目。同时，亚马逊也发布了雄心勃勃的计划，承诺在2030年前投资100亿美元用于推动可再生能源的创新和发展。】问题【谷歌公司的目标是什么】的答案是什么？"
    # text = "抽取式阅读理解任务：阅读文章【老师好，请问大电阻悬空只是对地才考虑吗，还是5.1千欧的电阻达不到大电阻的条件，就是上面这个引脚得出高电平的结论是因为它接大电阻悬空了，还是因为本身接了VCC所以是高电平，接在VCC上的电阻反正不管大还是小那个对应的引脚都是高电平，好像不需要考虑，大电阻悬空只可能会影响到本身信号是低电平，但是接了大电阻导致引脚悬空，用高电平来判断】问题【大电阻悬空只是对地才考虑吗】的答案是什么？"
    # 在当前深度学习领域，图神经网络（Graph Neural Networks, GNNs）被广泛用于图数据的学习任务，例如社交网络、分子结构分析等。在实际应用中，如何处理大规模图数据的效率问题成为一个关键挑战。请问，有哪些当前主流的方法或者技术用于加速大规模图神经网络的训练过程？这些方法的原理是什么，它们如何在实际任务中表现？在未来，我们是否可以期待更多创新的大规模图神经网络训练的加速技术的出现？

elif ch ==10:
    text = "多项选择任务：阅读文章【这大家千万不能着急，我们现在只是暂时输了7分。距离比赛结束还有20多分钟呢，我们是完全有机会转败为赢的，大家加油!】问题【说话人希望大家：】？{别得意/冷静一些/加快速度/提前预习}"
elif ch == 11:
    text = "自然语言推理任务：【小明昨天生病没有去上学】和【他昨天去参加体育课】，以上两句话的逻辑关系是什么？{无关/矛盾/蕴含}"
elif ch == 12:
    text = "指代消解任务：文章【李鸣觉得董客这人，踏实得叫人难受。可因为孟野和森森太疯，他只好去找董客聊天，但在董客眼里，李鸣也是不正常，他竟然放着现成的大学不愿上。】中{他指的是李鸣吗？}{是/不是}"
elif ch == 13:
    text = "语义匹配任务：【我很开心】和【我很高兴】，以上两句话的内容是否相似？{相似/不相似}"

############################################################################################################

# text = "文本分类任务：【钢琴块3别踩白块儿3钢琴块3是一款简洁的钢琴模拟软件,在Android平台上,类似的软件还是比较多的。】这篇文章的类别是什么？{相机/影视娱乐/棋牌中心/新闻/财经/策略/休闲益智/教育}"

# 使用tokenizer处理文本，得到tokenized的结果，padding和truncation用于处理不同长度的文本
encode_dict = tokenizer(text, max_length=1024, padding='max_length',truncation=True)

# 将tokenized的结果转换为PyTorch张量，包括input_ids和attention_mask
inputs = {
  "input_ids": torch.tensor([encode_dict['input_ids']]).long(),
  "attention_mask": torch.tensor([encode_dict['attention_mask']]).long(),
  }

# 生成预测
logits = model.generate(
  input_ids = inputs['input_ids'],
  max_length=100,       #生成的最大长度
  early_stopping=True,  #提前停止生成
  )
# 由于T5生成的结果第一个token是无效的，这里去掉第一个token
logits=logits[:,1:]

# 将生成的结果还原为文本，去掉特殊token
predict_label = [tokenizer.decode(i,skip_special_tokens=True) for i in logits]
print(predict_label)