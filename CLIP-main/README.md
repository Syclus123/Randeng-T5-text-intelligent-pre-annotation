## Taiyi-CLIP-Roberta图片分类智能预标注算法

### **算法介绍**

​	使用chinese-roberta-wwm作为中文语言编码器，使用WWM全字屏蔽增强了中文文本处理中的语言特征。将CLIP模型中的VIT-B-32应用于视觉编码器。在Noah-Wukong(100M)、Zero图文数据集上进行预训练。预标注标签可选用Imagenet数据集的21841类标签以及常见1000类标签进行约束。

### **创新点：**

1、支持多模态学习，能够在图像和文本之间建立强大的语义关系，更加全面理解图像内容。

2、采用RoBERTa中文编码器，更适合中文标签输入的智能预标注任务。

3、支持零样本学习，可准确推断未知类别，不受限于分类类别，具有极强扩展性。

4、可选用Imagenet的21841类别标签与常见1000类别标签自动填充，不需要人工给定标签，实现一键全智能预标注。

### **代码运行**

直接运行 main.py

### **代码说明**

​	main.py ——运行代码	

​	taiyi_http.py——模型运行

​	class_name——存储类名文件	

​	clip——clip模型文件

​	taiyiclip——taiyi-clip模型文件

​	clip32——VIT-patch32的图像编码器模型文件

​	requirements.txt——依赖文件

​	

​	